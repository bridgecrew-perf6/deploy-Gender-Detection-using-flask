{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from PIL import Image , ImageOps  \n",
    "from numpy import asarray\n",
    "from tensorflow.keras.layers import Input,Lambda,Dense,Flatten,GlobalMaxPool2D,Dropout\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "datadir=\"data/tm/test\"\n",
    "training_data=[]\n",
    "categories=[\"Male\",\"Female\"]\n",
    "for category in categories:\n",
    "    path=os.path.join(datadir,category)\n",
    "    class_num=categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (img_size, img_size))\n",
    "            training_data.append([image, class_num])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "random.shuffle(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for image,gender in training_data:\n",
    "    x_test.append(image)\n",
    "    y_test.append(gender)\n",
    "X_train=[]\n",
    "for i in range(len(x_test)):\n",
    "    img_array=asarray(x_test[i])\n",
    "    X_train.append(img_array)\n",
    "x_test=X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(x_test)\n",
    "x_test=x_test.reshape(-1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg =VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc1 = vgg.layers[-3]\n",
    "#fc2 = vgg.layers[-2]\n",
    "#predictions = vgg.layers[-1]\n",
    "\n",
    "# Create the dropout layers\n",
    "#dropout1 = Dropout(0.09)\n",
    "#dropout2 = Dropout(0.09)\n",
    "\n",
    "# Reconnect the layers\n",
    "#x = dropout1(fc1.output)\n",
    "#x = fc2(x)\n",
    "#predictors = predictions(x)\n",
    "#prediction= Flatten()(predictors)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "#out = Dense(2, activation='softmax')(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg.input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('data/tm/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = valid_datagen.flow_from_directory('data/tm/validation',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 94 steps, validate for 7 steps\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 395s 4s/step - loss: 0.5979 - accuracy: 0.7404 - val_loss: 0.3190 - val_accuracy: 0.8485\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 377s 4s/step - loss: 0.3250 - accuracy: 0.8506 - val_loss: 0.2953 - val_accuracy: 0.8535\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 411s 4s/step - loss: 0.2350 - accuracy: 0.9025 - val_loss: 0.2889 - val_accuracy: 0.8636\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 432s 5s/step - loss: 0.2480 - accuracy: 0.8948 - val_loss: 0.3354 - val_accuracy: 0.8434\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 434s 5s/step - loss: 0.1910 - accuracy: 0.9208 - val_loss: 0.3423 - val_accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "  training_set,\n",
    "  validation_data=validation_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(validation_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927920298879203\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred_final=[]\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred_final.append(y_pred[i][0])\n",
    "y_pred_final=np.round(y_pred_final)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_pred_final,y_test)\n",
    "model_accuracy=(cm[0][0]+cm[1][1]) / ( cm[1][0] + cm[0][1]+cm[0][0]+cm[1][1])\n",
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gender_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
